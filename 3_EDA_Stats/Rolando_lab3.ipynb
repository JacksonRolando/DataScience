{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 - EDA (Stats)\n",
    "### Jackson Rolando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Review of Statistical Tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My initial hypothesis:\n",
    "The GPAs of students who play video games regularly are significantly lower than those who do not.\n",
    "\n",
    "My answers to the questions:\n",
    "1. A two-sample t-test is be used to compare a measured continuous variable between two groups. \n",
    "2. This situation is perfect for a two-sampled t-test. There are two groups, gamers and non-gamers, and we have the continuous variable of a GPA. \n",
    "Are there any particular assumptions that the t-test makes that may not hold here?\n",
    "3. We don't know how our distributions fall. The test assumes a normal distribution, which we have no idea of confirming. The standard deviations are similar, but since they are close, and we have more than 30 samples in each category, the mismatch shouldn't be an issue.\n",
    "\n",
    "**Null Hypothesesis:** There is not a significant difference between the groups.\n",
    "\n",
    "**Alernative Hypothesesis:** There is a significant difference between the groups, and the gamers have a higher GPA. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we apply the two-sampled t-test on the sample data: \n",
    "> 68 students said they play video games regularly, while 32 students said they did not. The 68 games have an average GPA of 3.4 with a standard deviation of 1.2, while the 32 non-gamers have an average GPA of 3.3 with a standard deviation of 1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=0.39893881176878243, pvalue=0.6908062583072547)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "stats.ttest_ind_from_stats(3.4, 1.2, 68, 3.3, 1.1, 32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test yielded a p-value of 0.6908, way higher than the required maximum of 0.01. This means that we cannot reject the null hypothesis, as there is not a significant enough difference between the two groups of students."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the t-test cannot prove my initial hypothesis either. My mentioning of one group having 'significantly lower' GPAs was just another way of saying there was a significant negative difference, which the t-test disproved. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploring Additional Statistical Tests\n",
    "a.  List  the  two  types  of  variables  for  which  the  test  is  appropriate.    Indicate  any \n",
    "assumptions that you would need to be aware of. \n",
    " \n",
    "b. Write down the general forms of the null and alternative hypotheses (one sentence per \n",
    "hypothesis). \n",
    " \n",
    "c. In your own words, write what it would mean if the test did and did not indicate \n",
    "statistical significance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation and Linear Regression\n",
    "\n",
    "A test for linear correlation is best done between two (usually) continuous features measured from the same sample. The assumptions usually made are less focused on the metrics of the data itself, but more on how the data was collected (random samples of a population vs specificly chosen independent variables) and/or controlled (potential confounding variables kept constant or intentionally made random). These assumptions/decisions affect what kinds of conclusions you can draw from the test, and which results you can use. \n",
    "\n",
    "A null hypothesis would predict the slope of the line of best fit between *insert variable 1* and *insert veriable 2* is zero, potentially with a threshold P-value.\n",
    "\n",
    "An alternative hypothesis would hope that the line of best fit of a plot of *variable 1* and *variable 2* has a nonzero slope, potentially with a maximum P value of acceptance.\n",
    "\n",
    "If the test indicates statistical significance, then depending on the decisions made when measuring samples (random samples from a population? chosen independent variables? controlled confounding variables?), you could use either the $r^2$ value or the P value for an implication of correlation or causation. For example, if you're measuring a correlation between two variables of random samples of a population with verifyably random confounding variables, then a very high $r^2$ value could imply causation. A relatively high correlation could mean that there is another (known or unknown) factor affecting both variables relatively predictably. There's something interesting going on. \n",
    "\n",
    "If the test does not indicate statistical significance between the variables of the correlation/regression, then one almost certainly does not cause the other, and there probably isn't another variable that affects the two variables similarly. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kruskal-Wallis Test\n",
    "This test is used to test for differences in a measured variable between different categories. Unlike other tests, it assumes <u>the different categories have a similar distribution</u>, but doesn't assume *which* distribution. It takes in the measurement variables not directly, but instead as a list of ranks, with the smallest measured value getting a rank of 1 and the largest value getting a rank of the number of total measured values. \n",
    "\n",
    "A null hypothesis predicts that there is no difference in the ranks of the means of each similarly-distributed group. An alternative hypothesis predicts that there is a significant difference between the means of the various categories.\n",
    "\n",
    "If the test indicates significance, this indicates that the means of the measured variable are different between the groups, and the category may be a useful differentiator for the measured variable. If the test does not indicate significance, then the category probably isn't a great way to separate the sample for the measured variable. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi Squared Test\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
